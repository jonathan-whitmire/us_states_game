<html>
<head>
<title>parquet.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
parquet.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; parquet compat &quot;&quot;&quot;</span>

<span class="s2">from </span><span class="s1">distutils.version </span><span class="s2">import </span><span class="s1">LooseVersion</span>
<span class="s2">import </span><span class="s1">io</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">Any</span><span class="s2">, </span><span class="s1">AnyStr</span><span class="s2">, </span><span class="s1">Dict</span><span class="s2">, </span><span class="s1">List</span><span class="s2">, </span><span class="s1">Optional</span><span class="s2">, </span><span class="s1">Tuple</span>
<span class="s2">from </span><span class="s1">warnings </span><span class="s2">import </span><span class="s1">catch_warnings</span>

<span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">FilePathOrBuffer</span><span class="s2">, </span><span class="s1">StorageOptions</span>
<span class="s2">from </span><span class="s1">pandas.compat._optional </span><span class="s2">import </span><span class="s1">import_optional_dependency</span>
<span class="s2">from </span><span class="s1">pandas.errors </span><span class="s2">import </span><span class="s1">AbstractMethodError</span>
<span class="s2">from </span><span class="s1">pandas.util._decorators </span><span class="s2">import </span><span class="s1">doc</span>

<span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">DataFrame</span><span class="s2">, </span><span class="s1">MultiIndex</span><span class="s2">, </span><span class="s1">get_option</span>
<span class="s2">from </span><span class="s1">pandas.core </span><span class="s2">import </span><span class="s1">generic</span>

<span class="s2">from </span><span class="s1">pandas.io.common </span><span class="s2">import </span><span class="s1">IOHandles</span><span class="s2">, </span><span class="s1">get_handle</span><span class="s2">, </span><span class="s1">is_fsspec_url</span><span class="s2">, </span><span class="s1">stringify_path</span>


<span class="s2">def </span><span class="s1">get_engine(engine: str) -&gt; </span><span class="s3">&quot;BaseImpl&quot;</span><span class="s1">:</span>
    <span class="s0">&quot;&quot;&quot; return our implementation &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">engine == </span><span class="s3">&quot;auto&quot;</span><span class="s1">:</span>
        <span class="s1">engine = get_option(</span><span class="s3">&quot;io.parquet.engine&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">engine == </span><span class="s3">&quot;auto&quot;</span><span class="s1">:</span>
        <span class="s4"># try engines in this order</span>
        <span class="s1">engine_classes = [PyArrowImpl</span><span class="s2">, </span><span class="s1">FastParquetImpl]</span>

        <span class="s1">error_msgs = </span><span class="s3">&quot;&quot;</span>
        <span class="s2">for </span><span class="s1">engine_class </span><span class="s2">in </span><span class="s1">engine_classes:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">engine_class()</span>
            <span class="s2">except </span><span class="s1">ImportError </span><span class="s2">as </span><span class="s1">err:</span>
                <span class="s1">error_msgs += </span><span class="s3">&quot;</span><span class="s2">\n </span><span class="s3">- &quot; </span><span class="s1">+ str(err)</span>

        <span class="s2">raise </span><span class="s1">ImportError(</span>
            <span class="s3">&quot;Unable to find a usable engine; &quot;</span>
            <span class="s3">&quot;tried using: 'pyarrow', 'fastparquet'.</span><span class="s2">\n</span><span class="s3">&quot;</span>
            <span class="s3">&quot;A suitable version of &quot;</span>
            <span class="s3">&quot;pyarrow or fastparquet is required for parquet &quot;</span>
            <span class="s3">&quot;support.</span><span class="s2">\n</span><span class="s3">&quot;</span>
            <span class="s3">&quot;Trying to import the above resulted in these errors:&quot;</span>
            <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">error_msgs</span><span class="s2">}</span><span class="s3">&quot;</span>
        <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">engine == </span><span class="s3">&quot;pyarrow&quot;</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">PyArrowImpl()</span>
    <span class="s2">elif </span><span class="s1">engine == </span><span class="s3">&quot;fastparquet&quot;</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">FastParquetImpl()</span>

    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;engine must be one of 'pyarrow', 'fastparquet'&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_get_path_or_handle(</span>
    <span class="s1">path: FilePathOrBuffer</span><span class="s2">,</span>
    <span class="s1">fs: Any</span><span class="s2">,</span>
    <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
    <span class="s1">mode: str = </span><span class="s3">&quot;rb&quot;</span><span class="s2">,</span>
    <span class="s1">is_dir: bool = </span><span class="s2">False,</span>
<span class="s1">) -&gt; Tuple[FilePathOrBuffer</span><span class="s2">, </span><span class="s1">Optional[IOHandles]</span><span class="s2">, </span><span class="s1">Any]:</span>
    <span class="s0">&quot;&quot;&quot;File handling for PyArrow.&quot;&quot;&quot;</span>
    <span class="s1">path_or_handle = stringify_path(path)</span>
    <span class="s2">if </span><span class="s1">is_fsspec_url(path_or_handle) </span><span class="s2">and </span><span class="s1">fs </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">fsspec = import_optional_dependency(</span><span class="s3">&quot;fsspec&quot;</span><span class="s1">)</span>

        <span class="s1">fs</span><span class="s2">, </span><span class="s1">path_or_handle = fsspec.core.url_to_fs(</span>
            <span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">**(storage_options </span><span class="s2">or </span><span class="s1">{})</span>
        <span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">storage_options:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;storage_options passed with buffer or non-fsspec filepath&quot;</span><span class="s1">)</span>

    <span class="s1">handles = </span><span class="s2">None</span>
    <span class="s2">if </span><span class="s1">(</span>
        <span class="s2">not </span><span class="s1">fs</span>
        <span class="s2">and not </span><span class="s1">is_dir</span>
        <span class="s2">and </span><span class="s1">isinstance(path_or_handle</span><span class="s2">, </span><span class="s1">str)</span>
        <span class="s2">and not </span><span class="s1">os.path.isdir(path_or_handle)</span>
    <span class="s1">):</span>
        <span class="s4"># use get_handle only when we are very certain that it is not a directory</span>
        <span class="s4"># fsspec resources can also point to directories</span>
        <span class="s4"># this branch is used for example when reading from non-fsspec URLs</span>
        <span class="s1">handles = get_handle(path_or_handle</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">is_text=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">fs = </span><span class="s2">None</span>
        <span class="s1">path_or_handle = handles.handle</span>
    <span class="s2">return </span><span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">handles</span><span class="s2">, </span><span class="s1">fs</span>


<span class="s2">class </span><span class="s1">BaseImpl:</span>
    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">validate_dataframe(df: DataFrame):</span>

        <span class="s2">if not </span><span class="s1">isinstance(df</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;to_parquet only supports IO with DataFrames&quot;</span><span class="s1">)</span>

        <span class="s4"># must have value column names for all index levels (strings only)</span>
        <span class="s2">if </span><span class="s1">isinstance(df.columns</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
            <span class="s2">if not </span><span class="s1">all(</span>
                <span class="s1">x.inferred_type </span><span class="s2">in </span><span class="s1">{</span><span class="s3">&quot;string&quot;</span><span class="s2">, </span><span class="s3">&quot;empty&quot;</span><span class="s1">} </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">df.columns.levels</span>
            <span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;&quot;&quot; 
                    parquet must have string column names for all values in 
                     each level of the MultiIndex 
                    &quot;&quot;&quot;</span>
                <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">df.columns.inferred_type </span><span class="s2">not in </span><span class="s1">{</span><span class="s3">&quot;string&quot;</span><span class="s2">, </span><span class="s3">&quot;empty&quot;</span><span class="s1">}:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;parquet must have string column names&quot;</span><span class="s1">)</span>

        <span class="s4"># index level names must be strings</span>
        <span class="s1">valid_names = all(</span>
            <span class="s1">isinstance(name</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">df.index.names </span><span class="s2">if </span><span class="s1">name </span><span class="s2">is not None</span>
        <span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">valid_names:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Index level names must be strings&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">write(self</span><span class="s2">, </span><span class="s1">df: DataFrame</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">compression</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">raise </span><span class="s1">AbstractMethodError(self)</span>

    <span class="s2">def </span><span class="s1">read(self</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">columns=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">raise </span><span class="s1">AbstractMethodError(self)</span>


<span class="s2">class </span><span class="s1">PyArrowImpl(BaseImpl):</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">import_optional_dependency(</span>
            <span class="s3">&quot;pyarrow&quot;</span><span class="s2">, </span><span class="s1">extra=</span><span class="s3">&quot;pyarrow is required for parquet support.&quot;</span>
        <span class="s1">)</span>
        <span class="s2">import </span><span class="s1">pyarrow.parquet</span>

        <span class="s4"># import utils to register the pyarrow extension types</span>
        <span class="s2">import </span><span class="s1">pandas.core.arrays._arrow_utils  </span><span class="s4"># noqa</span>

        <span class="s1">self.api = pyarrow</span>

    <span class="s2">def </span><span class="s1">write(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">df: DataFrame</span><span class="s2">,</span>
        <span class="s1">path: FilePathOrBuffer[AnyStr]</span><span class="s2">,</span>
        <span class="s1">compression: Optional[str] = </span><span class="s3">&quot;snappy&quot;</span><span class="s2">,</span>
        <span class="s1">index: Optional[bool] = </span><span class="s2">None,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">partition_cols: Optional[List[str]] = </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">self.validate_dataframe(df)</span>

        <span class="s1">from_pandas_kwargs: Dict[str</span><span class="s2">, </span><span class="s1">Any] = {</span><span class="s3">&quot;schema&quot;</span><span class="s1">: kwargs.pop(</span><span class="s3">&quot;schema&quot;</span><span class="s2">, None</span><span class="s1">)}</span>
        <span class="s2">if </span><span class="s1">index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">from_pandas_kwargs[</span><span class="s3">&quot;preserve_index&quot;</span><span class="s1">] = index</span>

        <span class="s1">table = self.api.Table.from_pandas(df</span><span class="s2">, </span><span class="s1">**from_pandas_kwargs)</span>

        <span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">handles</span><span class="s2">, </span><span class="s1">kwargs[</span><span class="s3">&quot;filesystem&quot;</span><span class="s1">] = _get_path_or_handle(</span>
            <span class="s1">path</span><span class="s2">,</span>
            <span class="s1">kwargs.pop(</span><span class="s3">&quot;filesystem&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
            <span class="s1">mode=</span><span class="s3">&quot;wb&quot;</span><span class="s2">,</span>
            <span class="s1">is_dir=partition_cols </span><span class="s2">is not None,</span>
        <span class="s1">)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">partition_cols </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s4"># writes to multiple files under the given path</span>
                <span class="s1">self.api.parquet.write_to_dataset(</span>
                    <span class="s1">table</span><span class="s2">,</span>
                    <span class="s1">path_or_handle</span><span class="s2">,</span>
                    <span class="s1">compression=compression</span><span class="s2">,</span>
                    <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
                    <span class="s1">**kwargs</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s4"># write to single output file</span>
                <span class="s1">self.api.parquet.write_table(</span>
                    <span class="s1">table</span><span class="s2">, </span><span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">compression=compression</span><span class="s2">, </span><span class="s1">**kwargs</span>
                <span class="s1">)</span>
        <span class="s2">finally</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">handles </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">handles.close()</span>

    <span class="s2">def </span><span class="s1">read(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">path</span><span class="s2">,</span>
        <span class="s1">columns=</span><span class="s2">None,</span>
        <span class="s1">use_nullable_dtypes=</span><span class="s2">False,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">kwargs[</span><span class="s3">&quot;use_pandas_metadata&quot;</span><span class="s1">] = </span><span class="s2">True</span>

        <span class="s1">to_pandas_kwargs = {}</span>
        <span class="s2">if </span><span class="s1">use_nullable_dtypes:</span>
            <span class="s2">if </span><span class="s1">LooseVersion(self.api.__version__) &gt;= </span><span class="s3">&quot;0.16&quot;</span><span class="s1">:</span>
                <span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>

                <span class="s1">mapping = {</span>
                    <span class="s1">self.api.int8(): pd.Int8Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.int16(): pd.Int16Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.int32(): pd.Int32Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.int64(): pd.Int64Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.uint8(): pd.UInt8Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.uint16(): pd.UInt16Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.uint32(): pd.UInt32Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.uint64(): pd.UInt64Dtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.bool_(): pd.BooleanDtype()</span><span class="s2">,</span>
                    <span class="s1">self.api.string(): pd.StringDtype()</span><span class="s2">,</span>
                <span class="s1">}</span>
                <span class="s1">to_pandas_kwargs[</span><span class="s3">&quot;types_mapper&quot;</span><span class="s1">] = mapping.get</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;'use_nullable_dtypes=True' is only supported for pyarrow &gt;= 0.16 &quot;</span>
                    <span class="s3">f&quot;(</span><span class="s2">{</span><span class="s1">self.api.__version__</span><span class="s2">} </span><span class="s3">is installed&quot;</span>
                <span class="s1">)</span>

        <span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">handles</span><span class="s2">, </span><span class="s1">kwargs[</span><span class="s3">&quot;filesystem&quot;</span><span class="s1">] = _get_path_or_handle(</span>
            <span class="s1">path</span><span class="s2">,</span>
            <span class="s1">kwargs.pop(</span><span class="s3">&quot;filesystem&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
            <span class="s1">mode=</span><span class="s3">&quot;rb&quot;</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.api.parquet.read_table(</span>
                <span class="s1">path_or_handle</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">).to_pandas(**to_pandas_kwargs)</span>
        <span class="s2">finally</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">handles </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">handles.close()</span>


<span class="s2">class </span><span class="s1">FastParquetImpl(BaseImpl):</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s4"># since pandas is a dependency of fastparquet</span>
        <span class="s4"># we need to import on first use</span>
        <span class="s1">fastparquet = import_optional_dependency(</span>
            <span class="s3">&quot;fastparquet&quot;</span><span class="s2">, </span><span class="s1">extra=</span><span class="s3">&quot;fastparquet is required for parquet support.&quot;</span>
        <span class="s1">)</span>
        <span class="s1">self.api = fastparquet</span>

    <span class="s2">def </span><span class="s1">write(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">df: DataFrame</span><span class="s2">,</span>
        <span class="s1">path</span><span class="s2">,</span>
        <span class="s1">compression=</span><span class="s3">&quot;snappy&quot;</span><span class="s2">,</span>
        <span class="s1">index=</span><span class="s2">None,</span>
        <span class="s1">partition_cols=</span><span class="s2">None,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">self.validate_dataframe(df)</span>
        <span class="s4"># thriftpy/protocol/compact.py:339:</span>
        <span class="s4"># DeprecationWarning: tostring() is deprecated.</span>
        <span class="s4"># Use tobytes() instead.</span>

        <span class="s2">if </span><span class="s3">&quot;partition_on&quot; </span><span class="s2">in </span><span class="s1">kwargs </span><span class="s2">and </span><span class="s1">partition_cols </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Cannot use both partition_on and &quot;</span>
                <span class="s3">&quot;partition_cols. Use partition_cols for partitioning data&quot;</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s3">&quot;partition_on&quot; </span><span class="s2">in </span><span class="s1">kwargs:</span>
            <span class="s1">partition_cols = kwargs.pop(</span><span class="s3">&quot;partition_on&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">partition_cols </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">kwargs[</span><span class="s3">&quot;file_scheme&quot;</span><span class="s1">] = </span><span class="s3">&quot;hive&quot;</span>

        <span class="s4"># cannot use get_handle as write() does not accept file buffers</span>
        <span class="s1">path = stringify_path(path)</span>
        <span class="s2">if </span><span class="s1">is_fsspec_url(path):</span>
            <span class="s1">fsspec = import_optional_dependency(</span><span class="s3">&quot;fsspec&quot;</span><span class="s1">)</span>

            <span class="s4"># if filesystem is provided by fsspec, file must be opened in 'wb' mode.</span>
            <span class="s1">kwargs[</span><span class="s3">&quot;open_with&quot;</span><span class="s1">] = </span><span class="s2">lambda </span><span class="s1">path</span><span class="s2">, </span><span class="s1">_: fsspec.open(</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s3">&quot;wb&quot;</span><span class="s2">, </span><span class="s1">**(storage_options </span><span class="s2">or </span><span class="s1">{})</span>
            <span class="s1">).open()</span>
        <span class="s2">elif </span><span class="s1">storage_options:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;storage_options passed with file object or non-fsspec file path&quot;</span>
            <span class="s1">)</span>

        <span class="s2">with </span><span class="s1">catch_warnings(record=</span><span class="s2">True</span><span class="s1">):</span>
            <span class="s1">self.api.write(</span>
                <span class="s1">path</span><span class="s2">,</span>
                <span class="s1">df</span><span class="s2">,</span>
                <span class="s1">compression=compression</span><span class="s2">,</span>
                <span class="s1">write_index=index</span><span class="s2">,</span>
                <span class="s1">partition_on=partition_cols</span><span class="s2">,</span>
                <span class="s1">**kwargs</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">read(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">columns=</span><span class="s2">None, </span><span class="s1">storage_options: StorageOptions = </span><span class="s2">None, </span><span class="s1">**kwargs</span>
    <span class="s1">):</span>
        <span class="s1">use_nullable_dtypes = kwargs.pop(</span><span class="s3">&quot;use_nullable_dtypes&quot;</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">use_nullable_dtypes:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;The 'use_nullable_dtypes' argument is not supported for the &quot;</span>
                <span class="s3">&quot;fastparquet engine&quot;</span>
            <span class="s1">)</span>
        <span class="s1">path = stringify_path(path)</span>
        <span class="s1">parquet_kwargs = {}</span>
        <span class="s1">handles = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">is_fsspec_url(path):</span>
            <span class="s1">fsspec = import_optional_dependency(</span><span class="s3">&quot;fsspec&quot;</span><span class="s1">)</span>

            <span class="s1">parquet_kwargs[</span><span class="s3">&quot;open_with&quot;</span><span class="s1">] = </span><span class="s2">lambda </span><span class="s1">path</span><span class="s2">, </span><span class="s1">_: fsspec.open(</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s3">&quot;rb&quot;</span><span class="s2">, </span><span class="s1">**(storage_options </span><span class="s2">or </span><span class="s1">{})</span>
            <span class="s1">).open()</span>
        <span class="s2">elif </span><span class="s1">isinstance(path</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">and not </span><span class="s1">os.path.isdir(path):</span>
            <span class="s4"># use get_handle only when we are very certain that it is not a directory</span>
            <span class="s4"># fsspec resources can also point to directories</span>
            <span class="s4"># this branch is used for example when reading from non-fsspec URLs</span>
            <span class="s1">handles = get_handle(path</span><span class="s2">, </span><span class="s3">&quot;rb&quot;</span><span class="s2">, </span><span class="s1">is_text=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">path = handles.handle</span>
        <span class="s1">parquet_file = self.api.ParquetFile(path</span><span class="s2">, </span><span class="s1">**parquet_kwargs)</span>

        <span class="s1">result = parquet_file.to_pandas(columns=columns</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">if </span><span class="s1">handles </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">handles.close()</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s1">@doc(storage_options=generic._shared_docs[</span><span class="s3">&quot;storage_options&quot;</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">to_parquet(</span>
    <span class="s1">df: DataFrame</span><span class="s2">,</span>
    <span class="s1">path: Optional[FilePathOrBuffer] = </span><span class="s2">None,</span>
    <span class="s1">engine: str = </span><span class="s3">&quot;auto&quot;</span><span class="s2">,</span>
    <span class="s1">compression: Optional[str] = </span><span class="s3">&quot;snappy&quot;</span><span class="s2">,</span>
    <span class="s1">index: Optional[bool] = </span><span class="s2">None,</span>
    <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
    <span class="s1">partition_cols: Optional[List[str]] = </span><span class="s2">None,</span>
    <span class="s1">**kwargs</span><span class="s2">,</span>
<span class="s1">) -&gt; Optional[bytes]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Write a DataFrame to the parquet format. 
 
    Parameters 
    ---------- 
    df : DataFrame 
    path : str or file-like object, default None 
        If a string, it will be used as Root Directory path 
        when writing a partitioned dataset. By file-like object, 
        we refer to objects with a write() method, such as a file handle 
        (e.g. via builtin open function) or io.BytesIO. The engine 
        fastparquet does not accept file-like objects. If path is None, 
        a bytes object is returned. 
 
        .. versionchanged:: 1.2.0 
 
    engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto' 
        Parquet library to use. If 'auto', then the option 
        ``io.parquet.engine`` is used. The default ``io.parquet.engine`` 
        behavior is to try 'pyarrow', falling back to 'fastparquet' if 
        'pyarrow' is unavailable. 
    compression : {{'snappy', 'gzip', 'brotli', None}}, default 'snappy' 
        Name of the compression to use. Use ``None`` for no compression. 
    index : bool, default None 
        If ``True``, include the dataframe's index(es) in the file output. If 
        ``False``, they will not be written to the file. 
        If ``None``, similar to ``True`` the dataframe's index(es) 
        will be saved. However, instead of being saved as values, 
        the RangeIndex will be stored as a range in the metadata so it 
        doesn't require much space and is faster. Other indexes will 
        be included as columns in the file output. 
 
        .. versionadded:: 0.24.0 
 
    partition_cols : str or list, optional, default None 
        Column names by which to partition the dataset. 
        Columns are partitioned in the order they are given. 
        Must be None if path is not a string. 
 
        .. versionadded:: 0.24.0 
 
    {storage_options} 
 
        .. versionadded:: 1.2.0 
 
    kwargs 
        Additional keyword arguments passed to the engine 
 
    Returns 
    ------- 
    bytes if no path argument is provided else None 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">isinstance(partition_cols</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s1">partition_cols = [partition_cols]</span>
    <span class="s1">impl = get_engine(engine)</span>

    <span class="s1">path_or_buf: FilePathOrBuffer = io.BytesIO() </span><span class="s2">if </span><span class="s1">path </span><span class="s2">is None else </span><span class="s1">path</span>

    <span class="s1">impl.write(</span>
        <span class="s1">df</span><span class="s2">,</span>
        <span class="s1">path_or_buf</span><span class="s2">,</span>
        <span class="s1">compression=compression</span><span class="s2">,</span>
        <span class="s1">index=index</span><span class="s2">,</span>
        <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
        <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">path </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s2">assert </span><span class="s1">isinstance(path_or_buf</span><span class="s2">, </span><span class="s1">io.BytesIO)</span>
        <span class="s2">return </span><span class="s1">path_or_buf.getvalue()</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return None</span>


<span class="s2">def </span><span class="s1">read_parquet(</span>
    <span class="s1">path</span><span class="s2">,</span>
    <span class="s1">engine: str = </span><span class="s3">&quot;auto&quot;</span><span class="s2">,</span>
    <span class="s1">columns=</span><span class="s2">None,</span>
    <span class="s1">use_nullable_dtypes: bool = </span><span class="s2">False,</span>
    <span class="s1">**kwargs</span><span class="s2">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Load a parquet object from the file path, returning a DataFrame. 
 
    Parameters 
    ---------- 
    path : str, path object or file-like object 
        Any valid string path is acceptable. The string could be a URL. Valid 
        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is 
        expected. A local file could be: 
        ``file://localhost/path/to/table.parquet``. 
        A file URL can also be a path to a directory that contains multiple 
        partitioned parquet files. Both pyarrow and fastparquet support 
        paths to directories as well as file URLs. A directory path could be: 
        ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir`` 
 
        If you want to pass in a path object, pandas accepts any 
        ``os.PathLike``. 
 
        By file-like object, we refer to objects with a ``read()`` method, 
        such as a file handle (e.g. via builtin ``open`` function) 
        or ``StringIO``. 
    engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto' 
        Parquet library to use. If 'auto', then the option 
        ``io.parquet.engine`` is used. The default ``io.parquet.engine`` 
        behavior is to try 'pyarrow', falling back to 'fastparquet' if 
        'pyarrow' is unavailable. 
    columns : list, default=None 
        If not None, only these columns will be read from the file. 
    use_nullable_dtypes : bool, default False 
        If True, use dtypes that use ``pd.NA`` as missing value indicator 
        for the resulting DataFrame (only applicable for ``engine=&quot;pyarrow&quot;``). 
        As new dtypes are added that support ``pd.NA`` in the future, the 
        output with this option will change to use those dtypes. 
        Note: this is an experimental option, and behaviour (e.g. additional 
        support dtypes) may change without notice. 
 
        .. versionadded:: 1.2.0 
    **kwargs 
        Any additional kwargs are passed to the engine. 
 
    Returns 
    ------- 
    DataFrame 
    &quot;&quot;&quot;</span>
    <span class="s1">impl = get_engine(engine)</span>
    <span class="s2">return </span><span class="s1">impl.read(</span>
        <span class="s1">path</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">use_nullable_dtypes=use_nullable_dtypes</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">)</span>
</pre>
</body>
</html>